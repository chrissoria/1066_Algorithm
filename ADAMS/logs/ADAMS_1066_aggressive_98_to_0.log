--------------------------------------------------------------------------------------------------------
      name:  <unnamed>
       log:  /hdir/0/chrissoria/1066/ADAMS_1066_aggressive_98_to_0.log
  log type:  text
 opened on:   8 May 2024, 21:51:53

. 
. ** set sample inclusion
. egen in_samp = rowmiss(AAGE RELSCORE COGSCORE dementia cogtot27_imp2002 ragender raeduc)

. *525 people have no missingness across the board, mostly due to the cogscore variable
. *nobody is missing age
. egen in_AAGE = rowmiss(AAGE)

. *nobody is missing relscore
. egen in_RELSCORE = rowmiss(RELSCORE)

. *927 people missing a cogscore, only 589 people have a full cogscore
. egen in_COGSCORE = rowmiss(COGSCORE)

. *nobody is missing the dementia score
. egen in_dementia = rowmiss(dementia)

. *416 people are missing this score, 1,100 people have a score
. egen in_cogtot27_imp2002 = rowmiss(cogtot27_imp2002)

. *nobody is missing gender or education
. egen in_ragender = rowmiss(ragender)

. keep if in_samp == 0
(939 observations deleted)

. count
  577

. egen in_samp2 = rowmiss(hurd_p expert_p lasso_p)

. 
. keep if in_samp2 == 0
(69 observations deleted)

. count
  508

. 
. ** table 2 **
. tab female

     female |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |        226       44.49       44.49
          1 |        282       55.51      100.00
------------+-----------------------------------
      Total |        508      100.00

. tab AAGE_cat

   AAGE_cat |      Freq.     Percent        Cum.
------------+-----------------------------------
          1 |        258       50.79       50.79
          2 |        250       49.21      100.00
------------+-----------------------------------
      Total |        508      100.00

. tab educat

     educat |      Freq.     Percent        Cum.
------------+-----------------------------------
          1 |        230       45.28       45.28
          2 |        123       24.21       69.49
          3 |        155       30.51      100.00
------------+-----------------------------------
      Total |        508      100.00

. 
. 
. ** table 3 **
. ** identify cutpoints to maximize sensitivity and specificity [optimal]
. * http://www.haghish.com/statistics/stata-blog/stata-programming/download/cutpt.html
. 
. *****  1066 *****
. 
. *****************
. 
. * optimal
. set seed 1234

. gen fold = mod(_n, 10) + 1

. gen k_fold_dem_pred_1066 = .
(508 missing values generated)

. 
. forvalues i = 1/10 {
  2.     local train = "fold != `i'"
  3.     local test = "fold == `i'"
  4.     logit dementia COGSCORE RELSCORE aRECALLcs if `train' 
  5.     predict p_`i' if `test', pr
  6.     replace k_fold_dem_pred_1066 = p_`i' if `test'
  7.     drop p_`i'
  8. }

Iteration 0:  Log likelihood = -197.54546  
Iteration 1:  Log likelihood = -94.733289  
Iteration 2:  Log likelihood = -72.137739  
Iteration 3:  Log likelihood =  -70.00585  
Iteration 4:  Log likelihood = -69.980024  
Iteration 5:  Log likelihood = -69.979988  
Iteration 6:  Log likelihood = -69.979988  

Logistic regression                                     Number of obs =    458
                                                        LR chi2(3)    = 255.13
                                                        Prob > chi2   = 0.0000
Log likelihood = -69.979988                             Pseudo R2     = 0.6458

------------------------------------------------------------------------------
    dementia | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
    COGSCORE |  -.6185584   .1273707    -4.86   0.000    -.8682003   -.3689165
    RELSCORE |   .5370237   .1075363     4.99   0.000     .3262564     .747791
   aRECALLcs |  -.6331234   .1423687    -4.45   0.000     -.912161   -.3540858
       _cons |   6.871709   1.509121     4.55   0.000     3.913886    9.829532
------------------------------------------------------------------------------
(458 missing values generated)
(50 real changes made)

Iteration 0:  Log likelihood = -204.01803  
Iteration 1:  Log likelihood = -91.985932  
Iteration 2:  Log likelihood = -68.536103  
Iteration 3:  Log likelihood = -66.899851  
Iteration 4:  Log likelihood =  -66.88051  
Iteration 5:  Log likelihood = -66.880487  
Iteration 6:  Log likelihood = -66.880487  

Logistic regression                                     Number of obs =    457
                                                        LR chi2(3)    = 274.28
                                                        Prob > chi2   = 0.0000
Log likelihood = -66.880487                             Pseudo R2     = 0.6722

------------------------------------------------------------------------------
    dementia | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
    COGSCORE |  -.6895312   .1387518    -4.97   0.000    -.9614797   -.4175827
    RELSCORE |   .5885052   .1127843     5.22   0.000     .3674521    .8095584
   aRECALLcs |  -.5743154   .1397266    -4.11   0.000    -.8481745   -.3004562
       _cons |   7.587496   1.617172     4.69   0.000     4.417897     10.7571
------------------------------------------------------------------------------
(457 missing values generated)
(51 real changes made)

Iteration 0:  Log likelihood =  -208.8308  
Iteration 1:  Log likelihood = -97.539423  
Iteration 2:  Log likelihood = -75.133842  
Iteration 3:  Log likelihood =   -71.9385  
Iteration 4:  Log likelihood = -71.879036  
Iteration 5:  Log likelihood = -71.878844  
Iteration 6:  Log likelihood = -71.878844  

Logistic regression                                     Number of obs =    457
                                                        LR chi2(3)    = 273.90
                                                        Prob > chi2   = 0.0000
Log likelihood = -71.878844                             Pseudo R2     = 0.6558

------------------------------------------------------------------------------
    dementia | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
    COGSCORE |  -.6480102   .1234074    -5.25   0.000    -.8898843   -.4061362
    RELSCORE |   .5687889   .1077956     5.28   0.000     .3575135    .7800643
   aRECALLcs |  -.6437224   .1412694    -4.56   0.000    -.9206053   -.3668396
       _cons |   7.210376   1.469084     4.91   0.000     4.331024    10.08973
------------------------------------------------------------------------------
(457 missing values generated)
(51 real changes made)

Iteration 0:  Log likelihood = -202.38209  
Iteration 1:  Log likelihood = -92.778776  
Iteration 2:  Log likelihood = -69.079059  
Iteration 3:  Log likelihood =  -66.91681  
Iteration 4:  Log likelihood = -66.875203  
Iteration 5:  Log likelihood = -66.875193  
Iteration 6:  Log likelihood = -66.875193  

Logistic regression                                     Number of obs =    457
                                                        LR chi2(3)    = 271.01
                                                        Prob > chi2   = 0.0000
Log likelihood = -66.875193                             Pseudo R2     = 0.6696

------------------------------------------------------------------------------
    dementia | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
    COGSCORE |  -.6366206   .1235223    -5.15   0.000    -.8787199   -.3945213
    RELSCORE |   .5650689   .1126021     5.02   0.000     .3443728    .7857651
   aRECALLcs |  -.6489306   .1497587    -4.33   0.000    -.9424522    -.355409
       _cons |   7.016008   1.472153     4.77   0.000     4.130642    9.901375
------------------------------------------------------------------------------
(457 missing values generated)
(51 real changes made)

Iteration 0:  Log likelihood = -197.37681  
Iteration 1:  Log likelihood = -93.457498  
Iteration 2:  Log likelihood = -70.981595  
Iteration 3:  Log likelihood = -68.462682  
Iteration 4:  Log likelihood = -68.423334  
Iteration 5:  Log likelihood = -68.423244  
Iteration 6:  Log likelihood = -68.423244  

Logistic regression                                     Number of obs =    457
                                                        LR chi2(3)    = 257.91
                                                        Prob > chi2   = 0.0000
Log likelihood = -68.423244                             Pseudo R2     = 0.6533

------------------------------------------------------------------------------
    dementia | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
    COGSCORE |  -.5902808   .1207265    -4.89   0.000    -.8269005   -.3536612
    RELSCORE |   .6156478   .1142944     5.39   0.000      .391635    .8396607
   aRECALLcs |  -.6236202   .1457681    -4.28   0.000    -.9093205     -.33792
       _cons |   6.308952   1.421538     4.44   0.000     3.522789    9.095116
------------------------------------------------------------------------------
(457 missing values generated)
(51 real changes made)

Iteration 0:  Log likelihood = -205.63801  
Iteration 1:  Log likelihood = -90.407059  
Iteration 2:  Log likelihood =  -65.18151  
Iteration 3:  Log likelihood = -60.520359  
Iteration 4:  Log likelihood = -60.392691  
Iteration 5:  Log likelihood = -60.392315  
Iteration 6:  Log likelihood = -60.392315  

Logistic regression                                     Number of obs =    457
                                                        LR chi2(3)    = 290.49
                                                        Prob > chi2   = 0.0000
Log likelihood = -60.392315                             Pseudo R2     = 0.7063

------------------------------------------------------------------------------
    dementia | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
    COGSCORE |  -.6084587   .1290197    -4.72   0.000    -.8613327   -.3555847
    RELSCORE |    .763398   .1407827     5.42   0.000      .487469    1.039327
   aRECALLcs |  -.8034193   .1688144    -4.76   0.000    -1.134289   -.4725492
       _cons |   6.488894    1.50303     4.32   0.000     3.543009    9.434778
------------------------------------------------------------------------------
(457 missing values generated)
(51 real changes made)

Iteration 0:  Log likelihood = -202.38209  
Iteration 1:  Log likelihood = -93.558167  
Iteration 2:  Log likelihood = -69.299103  
Iteration 3:  Log likelihood = -67.002412  
Iteration 4:  Log likelihood = -66.957031  
Iteration 5:  Log likelihood = -66.957019  
Iteration 6:  Log likelihood = -66.957019  

Logistic regression                                     Number of obs =    457
                                                        LR chi2(3)    = 270.85
                                                        Prob > chi2   = 0.0000
Log likelihood = -66.957019                             Pseudo R2     = 0.6692

------------------------------------------------------------------------------
    dementia | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
    COGSCORE |  -.7272577    .135222    -5.38   0.000     -.992288   -.4622274
    RELSCORE |    .556487   .1105205     5.04   0.000     .3398709    .7731031
   aRECALLcs |  -.6173483   .1432164    -4.31   0.000    -.8980473   -.3366493
       _cons |   8.187466   1.610369     5.08   0.000       5.0312    11.34373
------------------------------------------------------------------------------
(457 missing values generated)
(51 real changes made)

Iteration 0:  Log likelihood = -207.24222  
Iteration 1:  Log likelihood =   -96.3978  
Iteration 2:  Log likelihood = -73.144487  
Iteration 3:  Log likelihood =  -71.38028  
Iteration 4:  Log likelihood =   -71.3533  
Iteration 5:  Log likelihood = -71.353255  
Iteration 6:  Log likelihood = -71.353255  

Logistic regression                                     Number of obs =    457
                                                        LR chi2(3)    = 271.78
                                                        Prob > chi2   = 0.0000
Log likelihood = -71.353255                             Pseudo R2     = 0.6557

------------------------------------------------------------------------------
    dementia | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
    COGSCORE |  -.6026289   .1197586    -5.03   0.000    -.8373513   -.3679064
    RELSCORE |   .5914736   .1101642     5.37   0.000     .3755556    .8073915
   aRECALLcs |  -.6352036    .140484    -4.52   0.000    -.9105472   -.3598601
       _cons |   6.532886   1.420369     4.60   0.000     3.749015    9.316758
------------------------------------------------------------------------------
(457 missing values generated)
(51 real changes made)

Iteration 0:  Log likelihood = -207.24222  
Iteration 1:  Log likelihood = -96.855793  
Iteration 2:  Log likelihood = -73.860376  
Iteration 3:  Log likelihood = -72.194442  
Iteration 4:  Log likelihood = -72.175856  
Iteration 5:  Log likelihood = -72.175836  
Iteration 6:  Log likelihood = -72.175836  

Logistic regression                                     Number of obs =    457
                                                        LR chi2(3)    = 270.13
                                                        Prob > chi2   = 0.0000
Log likelihood = -72.175836                             Pseudo R2     = 0.6517

------------------------------------------------------------------------------
    dementia | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
    COGSCORE |  -.6270456   .1198575    -5.23   0.000     -.861962   -.3921291
    RELSCORE |   .5827705   .1080002     5.40   0.000      .371094    .7944469
   aRECALLcs |  -.6002637   .1373871    -4.37   0.000    -.8695375   -.3309899
       _cons |   6.834554   1.418042     4.82   0.000     4.055242    9.613865
------------------------------------------------------------------------------
(457 missing values generated)
(51 real changes made)

Iteration 0:  Log likelihood = -202.55853  
Iteration 1:  Log likelihood = -96.148971  
Iteration 2:  Log likelihood = -74.378041  
Iteration 3:  Log likelihood = -72.533352  
Iteration 4:  Log likelihood = -72.512216  
Iteration 5:  Log likelihood = -72.512192  
Iteration 6:  Log likelihood = -72.512192  

Logistic regression                                     Number of obs =    458
                                                        LR chi2(3)    = 260.09
                                                        Prob > chi2   = 0.0000
Log likelihood = -72.512192                             Pseudo R2     = 0.6420

------------------------------------------------------------------------------
    dementia | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
    COGSCORE |  -.6157612   .1183827    -5.20   0.000     -.847787   -.3837355
    RELSCORE |   .5412108   .1070227     5.06   0.000     .3314501    .7509714
   aRECALLcs |  -.5946141    .140514    -4.23   0.000    -.8700164   -.3192118
       _cons |    6.75663   1.390355     4.86   0.000     4.031584    9.481677
------------------------------------------------------------------------------
(458 missing values generated)
(50 real changes made)

. 
. cutpt dementia k_fold_dem_pred_1066

Empirical cutpoint estimation
Method:                                Liu
Reference variable:                    dementia (0=neg, 1=pos)
Classification variable:               k_fold_dem_pred_1066
Empirical optimal cutpoint:            .14220728
Sensitivity at cutpoint:               0.94
Specificity at cutpoint:               0.90
Area under ROC curve at cutpoint:      0.92

. 
. gen k_fold_dem_pred_1066_opt = (k_fold_dem_pred_1066 >= .14220728) if !missing(k_fold_dem_pred_1066)

. tab dementia k_fold_dem_pred_1066_opt, matcell(conf_matrix)

           | k_fold_dem_pred_1066_
           |          opt
  dementia |         0          1 |     Total
-----------+----------------------+----------
         0 |       383         42 |       425 
         1 |         5         78 |        83 
-----------+----------------------+----------
     Total |       388        120 |       508 

. matrix list conf_matrix

conf_matrix[2,2]
     c1   c2
r1  383   42
r2    5   78

. 
. scalar TN = conf_matrix[1,1]

. scalar FN = conf_matrix[2,1]

. scalar FP = conf_matrix[1,2]

. scalar TP = conf_matrix[2,2]

. 
. scalar Sensitivity = TP / (TP + FN)

. scalar Specificity = TN / (TN + FP)

. scalar Accuracy = (TP + TN) / (TP + TN + FP + FN)

. scalar Prevalence = ((TP+FP) / (TP + TN + FP + FN))*100

. display TP+FP
120

. 
. display "Sensitivity for 1066 .25: " Sensitivity
Sensitivity for 1066 .25: .93975904

. display "Specificity for 1066 .25: " Specificity
Specificity for 1066 .25: .90117647

. display "Accuracy for 1066 .25: " Accuracy
Accuracy for 1066 .25: .90748031

. display "Predicted Prevalence for 1066 optimal: " Prevalence
Predicted Prevalence for 1066 optimal: 23.622047

. 
. display "Predicted Prevalence from 1066 optimal cutoff: " (120/508) * 100
Predicted Prevalence from 1066 optimal cutoff: 23.622047

. roctab dementia k_fold_dem_pred_1066

                      ROC                     Asymptotic normal  
           Obs       area     Std. err.      [95% conf. interval]
     ------------------------------------------------------------
           508     0.9701       0.0070        0.95636     0.98382

. rocreg dementia k_fold_dem_pred_1066
(running rocregstat on estimation sample)

Bootstrap replications (1,000): .........10.........20.........30.........40.........50.........60......
> ...70.........80.........90.........100.........110.........120.........130.........140.........150...
> ......160.........170.........180.........190.........200.........210.........220.........230.........
> 240.........250.........260.........270.........280.........290.........300.........310.........320...
> ......330.........340.........350.........360.........370.........380.........390.........400.........
> 410.........420.........430.........440.........450.........460.........470.........480.........490...
> ......500.........510.........520.........530.........540.........550.........560.........570.........
> 580.........590.........600.........610.........620.........630.........640.........650.........660...
> ......670.........680.........690.........700.........710.........720.........730.........740.........
> 750.........760.........770.........780.........790.........800.........810.........820.........830...
> ......840.........850.........860.........870.........880.........890.........900.........910.........
> 920.........930.........940.........950.........960.........970.........980.........990.........1,000 
> done

Bootstrap results                                        Number of obs =   508
                                                         Replications  = 1,000

Nonparametric ROC estimation

Control standardization: empirical
ROC method             : empirical

Area under the ROC curve

   Status    : dementia
   Classifier: k_fold_dem_pred_1066
------------------------------------------------------------------------------
             |    Observed               Bootstrap
         AUC | coefficient       Bias    std. err.     [95% conf. interval]
-------------+----------------------------------------------------------------
             |    .9700921  -.0000253    .0069986     .9563751   .9838092  (N)
             |                                        .9548286   .9824359  (P)
             |                                         .953027   .9816983 (BC)
------------------------------------------------------------------------------

. 
. matrix drop conf_matrix

. scalar drop TN FN FP TP Sensitivity Specificity Accuracy Prevalence

. *ascribed
. gen dem_pred_bin_1066a25 = (k_fold_dem_pred_1066 >= .25) if !missing(k_fold_dem_pred_1066)

. tab dem_pred_bin_1066a25

dem_pred_bi |
  n_1066a25 |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |        406       79.92       79.92
          1 |        102       20.08      100.00
------------+-----------------------------------
      Total |        508      100.00

. tab dementia dem_pred_bin_1066a25, matcell(conf_matrix)

           | dem_pred_bin_1066a25
  dementia |         0          1 |     Total
-----------+----------------------+----------
         0 |       394         31 |       425 
         1 |        12         71 |        83 
-----------+----------------------+----------
     Total |       406        102 |       508 

. 
. matrix list conf_matrix

conf_matrix[2,2]
     c1   c2
r1  394   31
r2   12   71

. 
. scalar TN = conf_matrix[1,1]

. scalar FN = conf_matrix[2,1]

. scalar FP = conf_matrix[1,2]

. scalar TP = conf_matrix[2,2]

. 
. scalar Sensitivity = TP / (TP + FN)

. scalar Specificity = TN / (TN + FP)

. scalar Accuracy = (TP + TN) / (TP + TN + FP + FN)

. scalar Prevalence = ((TP+FP) / (TP + TN + FP + FN))*100

. display TP+FP
102

. 
. display "Sensitivity for 1066 .25: " Sensitivity
Sensitivity for 1066 .25: .85542169

. display "Specificity for 1066 .25: " Specificity
Specificity for 1066 .25: .92705882

. display "Accuracy for 1066 .25: " Accuracy
Accuracy for 1066 .25: .91535433

. display "Predicted Prevalence for 1066 .25: " Prevalence
Predicted Prevalence for 1066 .25: 20.07874

. 
. roctab dementia dem_pred_bin_1066a25

                      ROC                     Asymptotic normal  
           Obs       area     Std. err.      [95% conf. interval]
     ------------------------------------------------------------
           508     0.8912       0.0204        0.85122     0.93126

. matrix drop conf_matrix

. scalar drop TN FN FP TP Sensitivity Specificity Accuracy Prevalence

. 
. *****  hrs, tics   ******
. 
. *************************
. 
. gen cogtot27_imp2002_binary = 2 if cogtot27_imp2002 <7
(417 missing values generated)

. replace cogtot27_imp2002_binary = 0 if cogtot27_imp2002 >6
(417 real changes made)

. 
. gen cogtot27_imp2002_categorical = 2 if cogtot27_imp2002 < 7
(417 missing values generated)

. replace cogtot27_imp2002_categorical = 1 if cogtot27_imp2002 >= 7 & cogtot27_imp2002 < 12
(174 real changes made)

. replace cogtot27_imp2002_categorical = 0 if cogtot27_imp2002 >= 12
(243 real changes made)

. 
. *binary tics
. gen dem_pred_lwa = 0

. replace dem_pred_lwa = 1 if cogtot27_imp2002 >= 0 & cogtot27_imp2002 <= 6
(91 real changes made)

. 
. 
. tab dem_pred_lwa

dem_pred_lw |
          a |      Freq.     Percent        Cum.
------------+-----------------------------------
          0 |        417       82.09       82.09
          1 |         91       17.91      100.00
------------+-----------------------------------
      Total |        508      100.00

. tab dementia dem_pred_lwa, matcell(conf_matrix)

           |     dem_pred_lwa
  dementia |         0          1 |     Total
-----------+----------------------+----------
         0 |       373         52 |       425 
         1 |        44         39 |        83 
-----------+----------------------+----------
     Total |       417         91 |       508 

. 
. matrix list conf_matrix

conf_matrix[2,2]
     c1   c2
r1  373   52
r2   44   39

. 
. scalar TN = conf_matrix[1,1]

. scalar FN = conf_matrix[2,1]

. scalar FP = conf_matrix[1,2]

. scalar TP = conf_matrix[2,2]

. 
. scalar Sensitivity = TP / (TP + FN)

. scalar Specificity = TN / (TN + FP)

. scalar Accuracy = (TP + TN) / (TP + TN + FP + FN)

. scalar Prevalence = ((TP+FP) / (TP + TN + FP + FN))*100

. 
. display "Sensitivity for tics ascribed: " Sensitivity
Sensitivity for tics ascribed: .46987952

. display "Specificity for tics ascribed: " Specificity
Specificity for tics ascribed: .87764706

. display "Accuracy for tics ascribed: " Accuracy
Accuracy for tics ascribed: .81102362

. 
. display "Predicted Prevalence from HRS TICS ascribed: " Prevalence
Predicted Prevalence from HRS TICS ascribed: 17.913386

. 
. roctab dementia dem_pred_lwa

                      ROC                     Asymptotic normal  
           Obs       area     Std. err.      [95% conf. interval]
     ------------------------------------------------------------
           508     0.6738       0.0287        0.61754     0.72998

. 
. *****  expert *****
. 
. *******************
. tabulate dementia expert_dem, matcell(conf_matrix)

           |      expert_dem
  dementia |         0          1 |     Total
-----------+----------------------+----------
         0 |       359         66 |       425 
         1 |        22         61 |        83 
-----------+----------------------+----------
     Total |       381        127 |       508 

. 
. matrix list conf_matrix

conf_matrix[2,2]
     c1   c2
r1  359   66
r2   22   61

. 
. scalar TN = conf_matrix[1,1]

. scalar FN = conf_matrix[2,1]

. scalar FP = conf_matrix[1,2]

. scalar TP = conf_matrix[2,2]

. 
. scalar Sensitivity = TP / (TP + FN)

. scalar Specificity = TN / (TN + FP)

. scalar Accuracy = (TP + TN) / (TP + TN + FP + FN)

. scalar Prevalence = ((TP+FP) / (TP + TN + FP + FN))*100

. 
. display "Sensitivity for expert ascribed: " Sensitivity
Sensitivity for expert ascribed: .73493976

. display "Specificity for expert ascribed: " Specificity
Specificity for expert ascribed: .84470588

. display "Accuracy for expert ascribed: " Accuracy
Accuracy for expert ascribed: .82677165

. display "Predicted Prevalence for expert ascribed: " Prevalence
Predicted Prevalence for expert ascribed: 25

. 
. roctab dementia expert_dem

                      ROC                     Asymptotic normal  
           Obs       area     Std. err.      [95% conf. interval]
     ------------------------------------------------------------
           508     0.7898       0.0259        0.73904     0.84060

. 
. *****  hurd  *****
. 
. ******************
. tabulate dementia hurd_dem, matcell(conf_matrix)

           |       hurd_dem
  dementia |         0          1 |     Total
-----------+----------------------+----------
         0 |       361         64 |       425 
         1 |        20         63 |        83 
-----------+----------------------+----------
     Total |       381        127 |       508 

. 
. matrix list conf_matrix

conf_matrix[2,2]
     c1   c2
r1  361   64
r2   20   63

. 
. scalar TN = conf_matrix[1,1]

. scalar FN = conf_matrix[2,1]

. scalar FP = conf_matrix[1,2]

. scalar TP = conf_matrix[2,2]

. 
. scalar Sensitivity = TP / (TP + FN)

. scalar Specificity = TN / (TN + FP)

. scalar Accuracy = (TP + TN) / (TP + TN + FP + FN)

. scalar Prevalence = ((TP+FP) / (TP + TN + FP + FN))*100

. 
. display "Sensitivity for hurd ascribed: " Sensitivity
Sensitivity for hurd ascribed: .75903614

. display "Specificity for hurd ascribed: " Specificity
Specificity for hurd ascribed: .84941176

. display "Accuracy for hurd ascribed: " Accuracy
Accuracy for hurd ascribed: .83464567

. display "Predicted Prevalence for hurd ascribed: " Prevalence
Predicted Prevalence for hurd ascribed: 25

. roctab dementia hurd_dem

                      ROC                     Asymptotic normal  
           Obs       area     Std. err.      [95% conf. interval]
     ------------------------------------------------------------
           508     0.8042       0.0252        0.75491     0.85354

. 
. ******  lasso  *******
. 
. **********************
. tabulate dementia lasso_dem, matcell(conf_matrix)

           |       lasso_dem
  dementia |         0          1 |     Total
-----------+----------------------+----------
         0 |       343         82 |       425 
         1 |        14         69 |        83 
-----------+----------------------+----------
     Total |       357        151 |       508 

. 
. matrix list conf_matrix

conf_matrix[2,2]
     c1   c2
r1  343   82
r2   14   69

. 
. scalar TN = conf_matrix[1,1]

. scalar FN = conf_matrix[2,1]

. scalar FP = conf_matrix[1,2]

. scalar TP = conf_matrix[2,2]

. 
. scalar Sensitivity = TP / (TP + FN)

. scalar Specificity = TN / (TN + FP)

. scalar Accuracy = (TP + TN) / (TP + TN + FP + FN)

. scalar Prevalence = ((TP+FP) / (TP + TN + FP + FN))*100

. 
. display "Sensitivity for lasso ascribed: " Sensitivity
Sensitivity for lasso ascribed: .8313253

. display "Specificity for lasso ascribed: " Specificity
Specificity for lasso ascribed: .80705882

. display "Accuracy for lasso ascribed: " Accuracy
Accuracy for lasso ascribed: .81102362

. display "Predicted Prevalence for lasso ascribed: " Prevalence
Predicted Prevalence for lasso ascribed: 29.724409

. 
. roctab dementia lasso_dem

                      ROC                     Asymptotic normal  
           Obs       area     Std. err.      [95% conf. interval]
     ------------------------------------------------------------
           508     0.8192       0.0228        0.77453     0.86386

. 
. ** education gradients [for all cutpoints]
. foreach dem_var in dementia k_fold_dem_pred_1066_opt dem_pred_bin_1066a25 dem_pred_lwa expert_dem hurd
> _dem lasso_dem {
  2.     forvalues r = 1/2 {
  3.         display "****start: `dem_var' `r'****"
  4.         qui: logit `dem_var' ib2.educat AAGE AAGE2 if AAGE_cat == `r'
  5.         margins educat, post  // Only use 'post' if necessary
  6.         eststo `dem_var'_`r'
  7.     }
  8. }
****start: dementia 1****

Predictive margins                                         Number of obs = 258
Model VCE: OIM

Expression: Pr(dementia), predict()

------------------------------------------------------------------------------
             |            Delta-method
             |     Margin   std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
      educat |
          1  |   .1334245   .0319917     4.17   0.000      .070722     .196127
          2  |   .0434133   .0244684     1.77   0.076    -.0045438    .0913704
          3  |   .0262196   .0182728     1.43   0.151    -.0095944    .0620336
------------------------------------------------------------------------------
****start: dementia 2****

Predictive margins                                         Number of obs = 250
Model VCE: OIM

Expression: Pr(dementia), predict()

------------------------------------------------------------------------------
             |            Delta-method
             |     Margin   std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
      educat |
          1  |   .2332591   .0368038     6.34   0.000     .1611249    .3053932
          2  |   .3324418   .0606255     5.48   0.000      .213618    .4512656
          3  |   .2236924    .046566     4.80   0.000     .1324247    .3149601
------------------------------------------------------------------------------
****start: k_fold_dem_pred_1066_opt 1****

Predictive margins                                         Number of obs = 258
Model VCE: OIM

Expression: Pr(k_fold_dem_pred_1066_opt), predict()

------------------------------------------------------------------------------
             |            Delta-method
             |     Margin   std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
      educat |
          1  |   .2407775   .0400959     6.01   0.000     .1621909    .3193641
          2  |   .0721809   .0309566     2.33   0.020     .0115071    .1328548
          3  |   .0393462   .0222109     1.77   0.076    -.0041864    .0828788
------------------------------------------------------------------------------
****start: k_fold_dem_pred_1066_opt 2****

Predictive margins                                         Number of obs = 250
Model VCE: OIM

Expression: Pr(k_fold_dem_pred_1066_opt), predict()

------------------------------------------------------------------------------
             |            Delta-method
             |     Margin   std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
      educat |
          1  |   .3996389   .0430975     9.27   0.000     .3151694    .4841085
          2  |   .3908176   .0636793     6.14   0.000     .2660086    .5156267
          3  |   .2096072   .0457146     4.59   0.000     .1200082    .2992063
------------------------------------------------------------------------------
****start: dem_pred_bin_1066a25 1****

Predictive margins                                         Number of obs = 258
Model VCE: OIM

Expression: Pr(dem_pred_bin_1066a25), predict()

------------------------------------------------------------------------------
             |            Delta-method
             |     Margin   std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
      educat |
          1  |   .1950895   .0370789     5.26   0.000     .1224162    .2677628
          2  |   .0582191    .028131     2.07   0.038     .0030833    .1133548
          3  |   .0394047   .0222326     1.77   0.076    -.0041704    .0829798
------------------------------------------------------------------------------
****start: dem_pred_bin_1066a25 2****

Predictive margins                                         Number of obs = 250
Model VCE: OIM

Expression: Pr(dem_pred_bin_1066a25), predict()

------------------------------------------------------------------------------
             |            Delta-method
             |     Margin   std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
      educat |
          1  |   .3481036   .0418204     8.32   0.000     .2661371    .4300702
          2  |    .299945   .0598431     5.01   0.000     .1826547    .4172353
          3  |   .1972077   .0445319     4.43   0.000     .1099269    .2844886
------------------------------------------------------------------------------
****start: dem_pred_lwa 1****

Predictive margins                                         Number of obs = 181
Model VCE: OIM

Expression: Pr(dem_pred_lwa), predict()

------------------------------------------------------------------------------
             |            Delta-method
             |     Margin   std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
      educat |
          1  |   .2688526   .0415922     6.46   0.000     .1873333    .3503719
          2  |   .0723179   .0310101     2.33   0.020     .0115392    .1330966
------------------------------------------------------------------------------
****start: dem_pred_lwa 2****

Predictive margins                                         Number of obs = 250
Model VCE: OIM

Expression: Pr(dem_pred_lwa), predict()

------------------------------------------------------------------------------
             |            Delta-method
             |     Margin   std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
      educat |
          1  |   .3362956    .042439     7.92   0.000     .2531166    .4194746
          2  |   .1867546   .0524497     3.56   0.000      .083955    .2895541
          3  |   .0690047   .0295266     2.34   0.019     .0111336    .1268758
------------------------------------------------------------------------------
****start: expert_dem 1****

Predictive margins                                         Number of obs = 258
Model VCE: OIM

Expression: Pr(expert_dem), predict()

------------------------------------------------------------------------------
             |            Delta-method
             |     Margin   std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
      educat |
          1  |   .1570962   .0331513     4.74   0.000     .0921209    .2220715
          2  |   .0890163   .0339875     2.62   0.009      .022402    .1556305
          3  |   .0264758   .0183513     1.44   0.149     -.009492    .0624436
------------------------------------------------------------------------------
****start: expert_dem 2****

Predictive margins                                         Number of obs = 250
Model VCE: OIM

Expression: Pr(expert_dem), predict()

------------------------------------------------------------------------------
             |            Delta-method
             |     Margin   std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
      educat |
          1  |   .4514162   .0432703    10.43   0.000     .3666081    .5362244
          2  |   .4970792   .0643813     7.72   0.000     .3708941    .6232642
          3  |   .2630504   .0488946     5.38   0.000     .1672187     .358882
------------------------------------------------------------------------------
****start: hurd_dem 1****

Predictive margins                                         Number of obs = 258
Model VCE: OIM

Expression: Pr(hurd_dem), predict()

------------------------------------------------------------------------------
             |            Delta-method
             |     Margin   std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
      educat |
          1  |   .1668961   .0344024     4.85   0.000     .0994687    .2343235
          2  |   .0883469   .0339862     2.60   0.009     .0217351    .1549586
          3  |   .0263801   .0183278     1.44   0.150    -.0095416    .0623019
------------------------------------------------------------------------------
****start: hurd_dem 2****

Predictive margins                                         Number of obs = 250
Model VCE: OIM

Expression: Pr(hurd_dem), predict()

------------------------------------------------------------------------------
             |            Delta-method
             |     Margin   std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
      educat |
          1  |   .4334503   .0429986    10.08   0.000     .3491746    .5177259
          2  |   .4611066   .0639527     7.21   0.000     .3357616    .5864517
          3  |    .304401   .0504198     6.04   0.000     .2055801    .4032219
------------------------------------------------------------------------------
****start: lasso_dem 1****

Predictive margins                                         Number of obs = 258
Model VCE: OIM

Expression: Pr(lasso_dem), predict()

------------------------------------------------------------------------------
             |            Delta-method
             |     Margin   std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
      educat |
          1  |   .2454019   .0389573     6.30   0.000     .1690469    .3217568
          2  |   .1182618   .0381553     3.10   0.002     .0434788    .1930449
          3  |   .0662672   .0281411     2.35   0.019     .0111117    .1214227
------------------------------------------------------------------------------
****start: lasso_dem 2****

Predictive margins                                         Number of obs = 250
Model VCE: OIM

Expression: Pr(lasso_dem), predict()

------------------------------------------------------------------------------
             |            Delta-method
             |     Margin   std. err.      z    P>|z|     [95% conf. interval]
-------------+----------------------------------------------------------------
      educat |
          1  |   .5087951   .0433165    11.75   0.000     .4238963    .5936939
          2  |   .4984019   .0638628     7.80   0.000     .3732331    .6235707
          3  |   .2928006   .0496152     5.90   0.000     .1955565    .3900447
------------------------------------------------------------------------------

. 
. *tabulating to see distribution
. tab AAGE_cat k_fold_dem_pred_1066_opt

           | k_fold_dem_pred_1066_
           |          opt
  AAGE_cat |         0          1 |     Total
-----------+----------------------+----------
         1 |       223         35 |       258 
         2 |       165         85 |       250 
-----------+----------------------+----------
     Total |       388        120 |       508 

. tab AAGE_cat dem_pred_bin_1066a25

           | dem_pred_bin_1066a25
  AAGE_cat |         0          1 |     Total
-----------+----------------------+----------
         1 |       229         29 |       258 
         2 |       177         73 |       250 
-----------+----------------------+----------
     Total |       406        102 |       508 

. tab AAGE_cat dem_pred_bin_lw
variable dem_pred_bin_lw not found
r(111);

end of do-file

r(111);

. do "/scratch/chrissoria/STATATMP/SD866859.000000"

. tab AAGE_cat dem_pred_lwa

           |     dem_pred_lwa
  AAGE_cat |         0          1 |     Total
-----------+----------------------+----------
         1 |       223         35 |       258 
         2 |       194         56 |       250 
-----------+----------------------+----------
     Total |       417         91 |       508 

. 
end of do-file

. do "/scratch/chrissoria/STATATMP/SD866859.000000"

. tab educat dem_pred_lwa

           |     dem_pred_lwa
    educat |         0          1 |     Total
-----------+----------------------+----------
         1 |       159         71 |       230 
         2 |       108         15 |       123 
         3 |       150          5 |       155 
-----------+----------------------+----------
     Total |       417         91 |       508 

. 
end of do-file

